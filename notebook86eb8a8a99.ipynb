{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-30T14:56:41.925169Z","iopub.execute_input":"2022-03-30T14:56:41.925928Z","iopub.status.idle":"2022-03-30T14:56:55.411657Z","shell.execute_reply.started":"2022-03-30T14:56:41.925875Z","shell.execute_reply":"2022-03-30T14:56:55.410763Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom IPython.display import Audio\nimport librosa\nfrom sklearn.neural_network import MLPClassifier\nimport os, glob, pickle\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-03-30T17:31:13.023543Z","iopub.execute_input":"2022-03-30T17:31:13.024168Z","iopub.status.idle":"2022-03-30T17:31:14.964904Z","shell.execute_reply.started":"2022-03-30T17:31:13.024013Z","shell.execute_reply":"2022-03-30T17:31:14.964148Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"paths = []\nlabels = []\nfor dirname, _, filenames in os.walk('../input/toronto-emotional-speech-set-tess'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        label = filename.split('_')[-1]\n        label = label.split('.')[0]\n        labels.append(label.lower())\n    if len(paths) == 2800:\n        break\nprint('Toronto Dataset is Loaded')\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:55.420239Z","iopub.execute_input":"2022-03-30T14:56:55.420484Z","iopub.status.idle":"2022-03-30T14:56:55.448161Z","shell.execute_reply.started":"2022-03-30T14:56:55.420443Z","shell.execute_reply":"2022-03-30T14:56:55.447561Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['speech'] = paths\ndf['label'] = labels\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:55.450707Z","iopub.execute_input":"2022-03-30T14:56:55.450923Z","iopub.status.idle":"2022-03-30T14:56:55.472001Z","shell.execute_reply.started":"2022-03-30T14:56:55.450896Z","shell.execute_reply":"2022-03-30T14:56:55.471416Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"emotion = 'fear'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nAudio(path)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:55.473038Z","iopub.execute_input":"2022-03-30T14:56:55.475423Z","iopub.status.idle":"2022-03-30T14:56:55.535037Z","shell.execute_reply.started":"2022-03-30T14:56:55.475334Z","shell.execute_reply":"2022-03-30T14:56:55.534270Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"emotion = 'angry'\npath = np.array(df['speech'][df['label']==emotion])[1]\ndata, sampling_rate = librosa.load(path)\nAudio(path)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:55.536190Z","iopub.execute_input":"2022-03-30T14:56:55.537013Z","iopub.status.idle":"2022-03-30T14:56:55.600059Z","shell.execute_reply.started":"2022-03-30T14:56:55.536973Z","shell.execute_reply":"2022-03-30T14:56:55.599507Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"emotion = 'disgust'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nAudio(path)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:55.601107Z","iopub.execute_input":"2022-03-30T14:56:55.601413Z","iopub.status.idle":"2022-03-30T14:56:55.680970Z","shell.execute_reply.started":"2022-03-30T14:56:55.601387Z","shell.execute_reply":"2022-03-30T14:56:55.680111Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"emotion = 'neutral'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nAudio(path)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:55.682276Z","iopub.execute_input":"2022-03-30T14:56:55.682677Z","iopub.status.idle":"2022-03-30T14:56:55.754203Z","shell.execute_reply.started":"2022-03-30T14:56:55.682636Z","shell.execute_reply":"2022-03-30T14:56:55.753217Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"emotion = 'sad'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nAudio(path)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:55.755843Z","iopub.execute_input":"2022-03-30T14:56:55.756138Z","iopub.status.idle":"2022-03-30T14:56:55.839099Z","shell.execute_reply.started":"2022-03-30T14:56:55.756102Z","shell.execute_reply":"2022-03-30T14:56:55.838227Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"emotion = 'ps'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nAudio(path)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:55.842191Z","iopub.execute_input":"2022-03-30T14:56:55.842890Z","iopub.status.idle":"2022-03-30T14:56:55.920713Z","shell.execute_reply.started":"2022-03-30T14:56:55.842849Z","shell.execute_reply":"2022-03-30T14:56:55.919872Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"emotion = 'happy'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata, sampling_rate = librosa.load(path)\nAudio(path)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:55.921836Z","iopub.execute_input":"2022-03-30T14:56:55.922053Z","iopub.status.idle":"2022-03-30T14:56:55.988782Z","shell.execute_reply.started":"2022-03-30T14:56:55.922026Z","shell.execute_reply":"2022-03-30T14:56:55.987983Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"def extract_mfcc(filename):\n    y, sr = librosa.load(filename, duration=3, offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n    return mfcc","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:55.990014Z","iopub.execute_input":"2022-03-30T14:56:55.990234Z","iopub.status.idle":"2022-03-30T14:56:55.994981Z","shell.execute_reply.started":"2022-03-30T14:56:55.990208Z","shell.execute_reply":"2022-03-30T14:56:55.994207Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"extract_mfcc(df['speech'][0])","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:55.996112Z","iopub.execute_input":"2022-03-30T14:56:55.996319Z","iopub.status.idle":"2022-03-30T14:56:56.050966Z","shell.execute_reply.started":"2022-03-30T14:56:55.996293Z","shell.execute_reply":"2022-03-30T14:56:56.050155Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:56.052510Z","iopub.execute_input":"2022-03-30T14:56:56.053000Z","iopub.status.idle":"2022-03-30T15:01:36.337216Z","shell.execute_reply.started":"2022-03-30T14:56:56.052953Z","shell.execute_reply":"2022-03-30T15:01:36.336244Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"X_mfcc","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:36.338916Z","iopub.execute_input":"2022-03-30T15:01:36.339453Z","iopub.status.idle":"2022-03-30T15:01:36.356033Z","shell.execute_reply.started":"2022-03-30T15:01:36.339410Z","shell.execute_reply":"2022-03-30T15:01:36.354882Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"X = [x for x in X_mfcc]\nX = np.array(X)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:36.357521Z","iopub.execute_input":"2022-03-30T15:01:36.357982Z","iopub.status.idle":"2022-03-30T15:01:36.368526Z","shell.execute_reply.started":"2022-03-30T15:01:36.357938Z","shell.execute_reply":"2022-03-30T15:01:36.367546Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"X = np.expand_dims(X, -1)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:14:13.586911Z","iopub.execute_input":"2022-03-30T15:14:13.587920Z","iopub.status.idle":"2022-03-30T15:14:13.594515Z","shell.execute_reply.started":"2022-03-30T15:14:13.587863Z","shell.execute_reply":"2022-03-30T15:14:13.593670Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\ny = enc.fit_transform(df[['label']])","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:14:26.431073Z","iopub.execute_input":"2022-03-30T15:14:26.431615Z","iopub.status.idle":"2022-03-30T15:14:26.467153Z","shell.execute_reply.started":"2022-03-30T15:14:26.431562Z","shell.execute_reply":"2022-03-30T15:14:26.466245Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"x, sr = librosa.load('../input/ravdess-emotional-speech-audio/Actor_04/03-01-01-01-01-02-04.wav')","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:36.370157Z","iopub.execute_input":"2022-03-30T15:01:36.370625Z","iopub.status.idle":"2022-03-30T15:01:36.567911Z","shell.execute_reply.started":"2022-03-30T15:01:36.370582Z","shell.execute_reply":"2022-03-30T15:01:36.567192Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"def extract_feature(file_name, mfcc, chroma, mel):\n    with soundfile.SoundFile(file_name) as sound_file:\n        X = sound_file.read(dtype=\"float32\")\n        sample_rate=sound_file.samplerate\n        if chroma:\n            stft=np.abs(librosa.stft(X))\n        result=np.array([])\n        if mfcc:\n            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n            result=np.hstack((result, mfccs))\n        if chroma:\n            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n            result=np.hstack((result, chroma))  \n        if mel:\n            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n            result=np.hstack((result, mel))\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:36.568902Z","iopub.execute_input":"2022-03-30T15:01:36.569733Z","iopub.status.idle":"2022-03-30T15:01:36.576478Z","shell.execute_reply.started":"2022-03-30T15:01:36.569696Z","shell.execute_reply":"2022-03-30T15:01:36.575854Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"emotions={\n  '01':'neutral',\n  '02':'calm',\n  '03':'happy',\n  '04':'sad',\n  '05':'angry',\n  '06':'fearful',\n  '07':'disgust',\n  '08':'surprised'\n}\n#DataFlair - Emotions to observe\nobserved_emotions=['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'suprised']","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:36.577653Z","iopub.execute_input":"2022-03-30T15:01:36.577875Z","iopub.status.idle":"2022-03-30T15:01:36.592784Z","shell.execute_reply.started":"2022-03-30T15:01:36.577848Z","shell.execute_reply":"2022-03-30T15:01:36.591895Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"def load_data(train_size=0.2):\n    x=[]\n    y=[]\n    for file in glob.glob('../input/ravdess-emotional-speech-audio'):\n        file_name=os.path.basename(file)\n        emotion = file_name.split('_')[-1]\n        emotion = emotion.split('.')[0]\n        if emotion not in observed_emotions:\n            continue\n        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n        x.append(feature)\n        y.append(emotion)\n    return train_test_split(np.array(x), y, test_size=0.7, random_state=9)\nprint('Ravdess dataset in Loaded')","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:36.593905Z","iopub.execute_input":"2022-03-30T15:01:36.594898Z","iopub.status.idle":"2022-03-30T15:01:36.605581Z","shell.execute_reply.started":"2022-03-30T15:01:36.594861Z","shell.execute_reply":"2022-03-30T15:01:36.604745Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:11:06.284579Z","iopub.execute_input":"2022-03-30T15:11:06.285381Z","iopub.status.idle":"2022-03-30T15:11:06.292642Z","shell.execute_reply.started":"2022-03-30T15:11:06.285330Z","shell.execute_reply":"2022-03-30T15:11:06.291715Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test=load_data(train_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:31:08.831945Z","iopub.execute_input":"2022-03-30T15:31:08.832254Z","iopub.status.idle":"2022-03-30T15:31:08.875066Z","shell.execute_reply.started":"2022-03-30T15:31:08.832219Z","shell.execute_reply":"2022-03-30T15:31:08.873850Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout\n\nmodel = Sequential([\n    LSTM(256, return_sequences=False, input_shape=(40,1)),\n    Dropout(0.2),\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(7, activation='softmax')\n])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:36.647988Z","iopub.status.idle":"2022-03-30T15:01:36.648783Z","shell.execute_reply.started":"2022-03-30T15:01:36.648511Z","shell.execute_reply":"2022-03-30T15:01:36.648543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:36.650146Z","iopub.status.idle":"2022-03-30T15:01:36.650612Z","shell.execute_reply.started":"2022-03-30T15:01:36.650345Z","shell.execute_reply":"2022-03-30T15:01:36.650389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:36.652061Z","iopub.status.idle":"2022-03-30T15:01:36.652534Z","shell.execute_reply.started":"2022-03-30T15:01:36.652268Z","shell.execute_reply":"2022-03-30T15:01:36.652291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:36.653545Z","iopub.status.idle":"2022-03-30T15:01:36.653975Z","shell.execute_reply.started":"2022-03-30T15:01:36.653743Z","shell.execute_reply":"2022-03-30T15:01:36.653768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}